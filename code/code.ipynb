{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "#-------------------------------\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg', disable = [\"tagger\", \"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              review sentiment\n",
       "0  Story of a man who has unnatural feelings for ...  negative\n",
       "1  Airport '77 starts as a brand new luxury 747 p...  negative\n",
       "2  This film lacked something I couldn't put my f...  negative\n",
       "3  Sorry everyone,,, I know this is supposed to b...  negative\n",
       "4  When I was little my parents took me along to ...  negative"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Story of a man who has unnatural feelings for ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>This film lacked something I couldn't put my f...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sorry everyone,,, I know this is supposed to b...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>When I was little my parents took me along to ...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              review sentiment\n",
       "0  Once again Mr. Costner has dragged out a movie...  negative\n",
       "1  This is an example of why the majority of acti...  negative\n",
       "2  First of all I hate those moronic rappers, who...  negative\n",
       "3  Not even the Beatles could write songs everyon...  negative\n",
       "4  Brass pictures (movies is not a fitting word f...  negative"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Once again Mr. Costner has dragged out a movie...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This is an example of why the majority of acti...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>First of all I hate those moronic rappers, who...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Not even the Beatles could write songs everyon...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Brass pictures (movies is not a fitting word f...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total=   9.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing mnb, total=   0.1s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.89      0.84     12500\n",
      "    positive       0.87      0.77      0.82     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.83      0.83      0.83     25000\n",
      "weighted avg       0.83      0.83      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([(\"vectorizer\", TfidfVectorizer()), (\"mnb\", MultinomialNB())], verbose=True)\n",
    "pipe.fit(train_data['review'], train_data['sentiment'])\n",
    "predClass = pipe.predict(test_data['review'])\n",
    "\n",
    "print(classification_report(test_data['sentiment'], predClass, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total=  10.1s\n",
      "[Pipeline] ............ (step 2 of 2) Processing logreg, total=   0.4s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88     12500\n",
      "    positive       0.87      0.88      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe2 = Pipeline([(\"vectorizer\", TfidfVectorizer()), (\"logreg\", SGDClassifier(loss = 'log', random_state=1234))], verbose=True)\n",
    "pipe2.fit(train_data['review'], train_data['sentiment'])\n",
    "predClass2 = pipe2.predict(test_data['review'])\n",
    "\n",
    "print(classification_report(test_data['sentiment'], predClass2, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total=  10.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing SVM, total=   0.9s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88     12500\n",
      "    positive       0.89      0.87      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "pipe3 = Pipeline([(\"vectorizer\", TfidfVectorizer()), (\"SVM\", LinearSVC(random_state=1234))], verbose=True)\n",
    "pipe3.fit(train_data['review'], train_data['sentiment'])\n",
    "predClass3 = pipe3.predict(test_data['review'])\n",
    "\n",
    "print(classification_report(test_data['sentiment'], predClass3, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class MeanSentenceVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def tokenizer(self, sentence):\n",
    "        doc = nlp(sentence)\n",
    "        preprocessed = [token.text for token in doc]\n",
    "        return preprocessed\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array(\n",
    "            [np.mean([nlp.vocab[word].vector for word in self.tokenizer(sentence)], axis=0) for sentence in tqdm(X)]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69087a9f67ca47d19ba157f0c59463a4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing SVM, total=   9.9s\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c4ee13b2c03469b8b796dbab4e182ed"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85     12500\n",
      "    positive       0.86      0.85      0.85     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe4 = Pipeline([(\"vectorizer\", MeanSentenceVectorizer()), (\"SVM\", LinearSVC(random_state=1234))], verbose=True)\n",
    "pipe4.fit(train_data['review'], train_data['sentiment'])\n",
    "predClass4 = pipe4.predict(test_data['review'])\n",
    "\n",
    "print(classification_report(test_data['sentiment'], predClass4, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "source": [
    "# Using tensorflow:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-97ecbf874269>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Slice the data for trials\n",
    "r = int(1/2 * len(train_data))\n",
    "\n",
    "tr_d = pd.concat([train_data[:r], train_data[12500:(12500+r)]])\n",
    "te_d = pd.concat([test_data[:r], test_data[12500:(12500+r)]])\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c3671de886749589a0e9dda6e565fa3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4864e1e4749455d95f47cf8521846ab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess Y\n",
    "y_train = np.array([0 if sent == 'negative' else 1 for sent in tqdm(tr_d['sentiment'])])\n",
    "y_test = np.array([0 if sent == 'negative' else 1 for sent in tqdm(te_d['sentiment'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess X\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import string\n",
    "import re\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(np.array(tr_d['review']), y_train, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1839"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "longest_text = max(X_train, key=len)\n",
    "num_words = len(longest_text.split(' '))\n",
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(standardize=custom_standardization, output_sequence_length = num_words)\n",
    "vectorize_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_layer(X_train)\n",
    "x_val = vectorize_layer(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(vectorize_layer.get_vocabulary())\n",
    "embd_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_4 (Embedding)      (None, 1839, 100)         9941500   \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 1839, 100)         0         \n_________________________________________________________________\nconv1d_4 (Conv1D)            (None, 611, 128)          89728     \n_________________________________________________________________\nglobal_max_pooling1d_4 (Glob (None, 128)               0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 10,047,869\nTrainable params: 10,047,869\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "np.random.seed(seed=12345)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(num_words, embd_dim, input_length=x_train.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "\"\"\" model.add(Dense(\n",
    "    300, activation='relu', input_shape = (X_train.shape[1],), \n",
    "    kernel_regularizer=l2(1e-5),\n",
    "    bias_regularizer=l2(1e-5),\n",
    "    activity_regularizer=l2(1e-5)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(\n",
    "    Dense(100, activation='relu',\n",
    "    kernel_regularizer=l2(1e-5),\n",
    "    bias_regularizer=l2(1e-5),\n",
    "    activity_regularizer=l2(1e-5)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid')) \"\"\"\n",
    "\n",
    "\n",
    "model.compile(loss = binary_crossentropy, optimizer = Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "160/160 [==============================] - 65s 398ms/step - loss: 0.5618 - accuracy: 0.6640 - val_loss: 0.3604 - val_accuracy: 0.8494\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 78s 490ms/step - loss: 0.1894 - accuracy: 0.9289 - val_loss: 0.2976 - val_accuracy: 0.8880\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 115s 722ms/step - loss: 0.0710 - accuracy: 0.9751 - val_loss: 0.3459 - val_accuracy: 0.8892\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 103s 646ms/step - loss: 0.0354 - accuracy: 0.9880 - val_loss: 0.4132 - val_accuracy: 0.8820\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.4607 - val_accuracy: 0.8802\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.0198 - accuracy: 0.9924 - val_loss: 0.4807 - val_accuracy: 0.8830\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 112s 704ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 0.4441 - val_accuracy: 0.8760\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 111s 696ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.5406 - val_accuracy: 0.8768\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 109s 684ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.5020 - val_accuracy: 0.8764\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 103s 647ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.6531 - val_accuracy: 0.8774\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size = 125, epochs = 10, verbose = 1, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200/200 [==============================] - 21s 105ms/step - loss: 0.7060 - accuracy: 0.8584\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.705986499786377, 0.8583599925041199]"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "x_test = vectorize_layer(np.array(te_d['review']))\n",
    "model.evaluate(x_test, y_test, batch_size = 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "msv = MeanSentenceVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cdfd9d9aef50492fb61edd2fe8cc9231"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd70c29511e64eb6b3e7cd5059413181"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess Y\n",
    "y_train = np.array([0 if sent == 'negative' else 1 for sent in tqdm(tr_d['sentiment'])])\n",
    "y_test = np.array([0 if sent == 'negative' else 1 for sent in tqdm(te_d['sentiment'])])\n",
    "tr_d_msv = msv.transform(tr_d['review'])\n",
    "te_d_msv = msv.transform(te_d['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(tr_d_msv, y_train, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_18\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_56 (Dense)             (None, 300)               90300     \n_________________________________________________________________\ndense_57 (Dense)             (None, 300)               90300     \n_________________________________________________________________\ndense_58 (Dense)             (None, 300)               90300     \n_________________________________________________________________\ndense_59 (Dense)             (None, 1)                 301       \n=================================================================\nTotal params: 271,201\nTrainable params: 271,201\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=12345)\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(300, activation=\"relu\", input_shape=(300,),\n",
    "    kernel_regularizer=l2(1e-5),\n",
    "    bias_regularizer=l2(1e-5),\n",
    "    activity_regularizer=l2(1e-5)))\n",
    "model2.add(Dense(300, activation=\"relu\",\n",
    "    kernel_regularizer=l2(1e-5),\n",
    "    bias_regularizer=l2(1e-5),\n",
    "    activity_regularizer=l2(1e-5)))\n",
    "model2.add(Dense(300, activation=\"relu\",\n",
    "    kernel_regularizer=l2(1e-5),\n",
    "    bias_regularizer=l2(1e-5),\n",
    "    activity_regularizer=l2(1e-5)))\n",
    "model2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model2.compile(loss = binary_crossentropy, optimizer = Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "160/160 - 3s - loss: 0.4559 - accuracy: 0.7876 - val_loss: 0.3712 - val_accuracy: 0.8384\n",
      "Epoch 2/100\n",
      "160/160 - 1s - loss: 0.3769 - accuracy: 0.8385 - val_loss: 0.3543 - val_accuracy: 0.8544\n",
      "Epoch 3/100\n",
      "160/160 - 1s - loss: 0.3595 - accuracy: 0.8485 - val_loss: 0.3509 - val_accuracy: 0.8482\n",
      "Epoch 4/100\n",
      "160/160 - 1s - loss: 0.3560 - accuracy: 0.8460 - val_loss: 0.3949 - val_accuracy: 0.8290\n",
      "Epoch 5/100\n",
      "160/160 - 1s - loss: 0.3664 - accuracy: 0.8404 - val_loss: 0.3626 - val_accuracy: 0.8410\n",
      "Epoch 6/100\n",
      "160/160 - 1s - loss: 0.3465 - accuracy: 0.8528 - val_loss: 0.3633 - val_accuracy: 0.8418\n",
      "Epoch 7/100\n",
      "160/160 - 1s - loss: 0.3521 - accuracy: 0.8481 - val_loss: 0.3439 - val_accuracy: 0.8548\n",
      "Epoch 8/100\n",
      "160/160 - 1s - loss: 0.3405 - accuracy: 0.8535 - val_loss: 0.3451 - val_accuracy: 0.8530\n",
      "Epoch 9/100\n",
      "160/160 - 1s - loss: 0.3428 - accuracy: 0.8535 - val_loss: 0.3497 - val_accuracy: 0.8518\n",
      "Epoch 10/100\n",
      "160/160 - 1s - loss: 0.3404 - accuracy: 0.8561 - val_loss: 0.3371 - val_accuracy: 0.8570\n",
      "Epoch 11/100\n",
      "160/160 - 1s - loss: 0.3373 - accuracy: 0.8583 - val_loss: 0.3475 - val_accuracy: 0.8490\n",
      "Epoch 12/100\n",
      "160/160 - 1s - loss: 0.3375 - accuracy: 0.8566 - val_loss: 0.3560 - val_accuracy: 0.8386\n",
      "Epoch 13/100\n",
      "160/160 - 1s - loss: 0.3405 - accuracy: 0.8564 - val_loss: 0.4539 - val_accuracy: 0.7720\n",
      "Epoch 14/100\n",
      "160/160 - 1s - loss: 0.3380 - accuracy: 0.8571 - val_loss: 0.3412 - val_accuracy: 0.8568\n",
      "Epoch 15/100\n",
      "160/160 - 1s - loss: 0.3312 - accuracy: 0.8593 - val_loss: 0.3594 - val_accuracy: 0.8452\n",
      "Epoch 16/100\n",
      "160/160 - 1s - loss: 0.3230 - accuracy: 0.8651 - val_loss: 0.3528 - val_accuracy: 0.8494\n",
      "Epoch 17/100\n",
      "160/160 - 1s - loss: 0.3336 - accuracy: 0.8601 - val_loss: 0.3499 - val_accuracy: 0.8518\n",
      "Epoch 18/100\n",
      "160/160 - 1s - loss: 0.3344 - accuracy: 0.8577 - val_loss: 0.3364 - val_accuracy: 0.8554\n",
      "Epoch 19/100\n",
      "160/160 - 1s - loss: 0.3285 - accuracy: 0.8641 - val_loss: 0.3739 - val_accuracy: 0.8370\n",
      "Epoch 20/100\n",
      "160/160 - 1s - loss: 0.3267 - accuracy: 0.8634 - val_loss: 0.3373 - val_accuracy: 0.8574\n",
      "Epoch 21/100\n",
      "160/160 - 1s - loss: 0.3277 - accuracy: 0.8619 - val_loss: 0.3347 - val_accuracy: 0.8596\n",
      "Epoch 22/100\n",
      "160/160 - 1s - loss: 0.3224 - accuracy: 0.8657 - val_loss: 0.3352 - val_accuracy: 0.8606\n",
      "Epoch 23/100\n",
      "160/160 - 1s - loss: 0.3224 - accuracy: 0.8655 - val_loss: 0.3345 - val_accuracy: 0.8600\n",
      "Epoch 24/100\n",
      "160/160 - 1s - loss: 0.3173 - accuracy: 0.8678 - val_loss: 0.3399 - val_accuracy: 0.8548\n",
      "Epoch 25/100\n",
      "160/160 - 1s - loss: 0.3170 - accuracy: 0.8682 - val_loss: 0.3588 - val_accuracy: 0.8442\n",
      "Epoch 26/100\n",
      "160/160 - 1s - loss: 0.3202 - accuracy: 0.8655 - val_loss: 0.3453 - val_accuracy: 0.8550\n",
      "Epoch 27/100\n",
      "160/160 - 1s - loss: 0.3186 - accuracy: 0.8700 - val_loss: 0.3407 - val_accuracy: 0.8558\n",
      "Epoch 28/100\n",
      "160/160 - 1s - loss: 0.3158 - accuracy: 0.8702 - val_loss: 0.3411 - val_accuracy: 0.8596\n",
      "Epoch 29/100\n",
      "160/160 - 1s - loss: 0.3143 - accuracy: 0.8721 - val_loss: 0.3405 - val_accuracy: 0.8572\n",
      "Epoch 30/100\n",
      "160/160 - 1s - loss: 0.3124 - accuracy: 0.8735 - val_loss: 0.3428 - val_accuracy: 0.8620\n",
      "Epoch 31/100\n",
      "160/160 - 1s - loss: 0.3175 - accuracy: 0.8684 - val_loss: 0.3476 - val_accuracy: 0.8530\n",
      "Epoch 32/100\n",
      "160/160 - 1s - loss: 0.3094 - accuracy: 0.8746 - val_loss: 0.3731 - val_accuracy: 0.8488\n",
      "Epoch 33/100\n",
      "160/160 - 1s - loss: 0.3166 - accuracy: 0.8689 - val_loss: 0.3540 - val_accuracy: 0.8528\n",
      "Epoch 34/100\n",
      "160/160 - 1s - loss: 0.3121 - accuracy: 0.8723 - val_loss: 0.3445 - val_accuracy: 0.8590\n",
      "Epoch 35/100\n",
      "160/160 - 1s - loss: 0.3046 - accuracy: 0.8738 - val_loss: 0.3426 - val_accuracy: 0.8570\n",
      "Epoch 36/100\n",
      "160/160 - 1s - loss: 0.3113 - accuracy: 0.8724 - val_loss: 0.3421 - val_accuracy: 0.8600\n",
      "Epoch 37/100\n",
      "160/160 - 1s - loss: 0.3046 - accuracy: 0.8774 - val_loss: 0.3513 - val_accuracy: 0.8570\n",
      "Epoch 38/100\n",
      "160/160 - 1s - loss: 0.3088 - accuracy: 0.8720 - val_loss: 0.3463 - val_accuracy: 0.8562\n",
      "Epoch 39/100\n",
      "160/160 - 1s - loss: 0.3040 - accuracy: 0.8763 - val_loss: 0.3560 - val_accuracy: 0.8526\n",
      "Epoch 40/100\n",
      "160/160 - 1s - loss: 0.3075 - accuracy: 0.8773 - val_loss: 0.3616 - val_accuracy: 0.8526\n",
      "Epoch 41/100\n",
      "160/160 - 1s - loss: 0.3061 - accuracy: 0.8756 - val_loss: 0.3510 - val_accuracy: 0.8546\n",
      "Epoch 42/100\n",
      "160/160 - 1s - loss: 0.3040 - accuracy: 0.8790 - val_loss: 0.3681 - val_accuracy: 0.8534\n",
      "Epoch 43/100\n",
      "160/160 - 1s - loss: 0.3057 - accuracy: 0.8763 - val_loss: 0.3451 - val_accuracy: 0.8612\n",
      "Epoch 44/100\n",
      "160/160 - 1s - loss: 0.3003 - accuracy: 0.8795 - val_loss: 0.3572 - val_accuracy: 0.8552\n",
      "Epoch 45/100\n",
      "160/160 - 1s - loss: 0.2966 - accuracy: 0.8820 - val_loss: 0.3539 - val_accuracy: 0.8602\n",
      "Epoch 46/100\n",
      "160/160 - 1s - loss: 0.3048 - accuracy: 0.8751 - val_loss: 0.3428 - val_accuracy: 0.8606\n",
      "Epoch 47/100\n",
      "160/160 - 2s - loss: 0.3018 - accuracy: 0.8778 - val_loss: 0.3476 - val_accuracy: 0.8576\n",
      "Epoch 48/100\n",
      "160/160 - 1s - loss: 0.2986 - accuracy: 0.8814 - val_loss: 0.3531 - val_accuracy: 0.8532\n",
      "Epoch 49/100\n",
      "160/160 - 1s - loss: 0.3007 - accuracy: 0.8775 - val_loss: 0.3430 - val_accuracy: 0.8610\n",
      "Epoch 50/100\n",
      "160/160 - 1s - loss: 0.2972 - accuracy: 0.8795 - val_loss: 0.3828 - val_accuracy: 0.8430\n",
      "Epoch 51/100\n",
      "160/160 - 1s - loss: 0.3018 - accuracy: 0.8781 - val_loss: 0.3557 - val_accuracy: 0.8564\n",
      "Epoch 52/100\n",
      "160/160 - 1s - loss: 0.2945 - accuracy: 0.8833 - val_loss: 0.3609 - val_accuracy: 0.8552\n",
      "Epoch 53/100\n",
      "160/160 - 1s - loss: 0.2989 - accuracy: 0.8798 - val_loss: 0.3665 - val_accuracy: 0.8494\n",
      "Epoch 54/100\n",
      "160/160 - 1s - loss: 0.2962 - accuracy: 0.8824 - val_loss: 0.3539 - val_accuracy: 0.8618\n",
      "Epoch 55/100\n",
      "160/160 - 1s - loss: 0.2965 - accuracy: 0.8825 - val_loss: 0.3704 - val_accuracy: 0.8524\n",
      "Epoch 56/100\n",
      "160/160 - 1s - loss: 0.3027 - accuracy: 0.8775 - val_loss: 0.3623 - val_accuracy: 0.8572\n",
      "Epoch 57/100\n",
      "160/160 - 1s - loss: 0.3059 - accuracy: 0.8758 - val_loss: 0.3627 - val_accuracy: 0.8506\n",
      "Epoch 58/100\n",
      "160/160 - 1s - loss: 0.2937 - accuracy: 0.8831 - val_loss: 0.3622 - val_accuracy: 0.8580\n",
      "Epoch 59/100\n",
      "160/160 - 1s - loss: 0.2907 - accuracy: 0.8862 - val_loss: 0.4321 - val_accuracy: 0.8432\n",
      "Epoch 60/100\n",
      "160/160 - 1s - loss: 0.3033 - accuracy: 0.8777 - val_loss: 0.3583 - val_accuracy: 0.8584\n",
      "Epoch 61/100\n",
      "160/160 - 1s - loss: 0.2976 - accuracy: 0.8809 - val_loss: 0.4088 - val_accuracy: 0.8340\n",
      "Epoch 62/100\n",
      "160/160 - 1s - loss: 0.3016 - accuracy: 0.8799 - val_loss: 0.3830 - val_accuracy: 0.8470\n",
      "Epoch 63/100\n",
      "160/160 - 1s - loss: 0.3018 - accuracy: 0.8788 - val_loss: 0.3814 - val_accuracy: 0.8452\n",
      "Epoch 64/100\n",
      "160/160 - 1s - loss: 0.3027 - accuracy: 0.8781 - val_loss: 0.3656 - val_accuracy: 0.8544\n",
      "Epoch 65/100\n",
      "160/160 - 1s - loss: 0.2962 - accuracy: 0.8806 - val_loss: 0.3618 - val_accuracy: 0.8532\n",
      "Epoch 66/100\n",
      "160/160 - 1s - loss: 0.2904 - accuracy: 0.8861 - val_loss: 0.3561 - val_accuracy: 0.8546\n",
      "Epoch 67/100\n",
      "160/160 - 1s - loss: 0.2964 - accuracy: 0.8843 - val_loss: 0.3614 - val_accuracy: 0.8574\n",
      "Epoch 68/100\n",
      "160/160 - 1s - loss: 0.2936 - accuracy: 0.8835 - val_loss: 0.3660 - val_accuracy: 0.8576\n",
      "Epoch 69/100\n",
      "160/160 - 1s - loss: 0.2941 - accuracy: 0.8845 - val_loss: 0.3588 - val_accuracy: 0.8552\n",
      "Epoch 70/100\n",
      "160/160 - 1s - loss: 0.2918 - accuracy: 0.8842 - val_loss: 0.3597 - val_accuracy: 0.8560\n",
      "Epoch 71/100\n",
      "160/160 - 1s - loss: 0.2921 - accuracy: 0.8838 - val_loss: 0.3573 - val_accuracy: 0.8578\n",
      "Epoch 72/100\n",
      "160/160 - 1s - loss: 0.2970 - accuracy: 0.8827 - val_loss: 0.3805 - val_accuracy: 0.8458\n",
      "Epoch 73/100\n",
      "160/160 - 1s - loss: 0.2890 - accuracy: 0.8873 - val_loss: 0.3726 - val_accuracy: 0.8524\n",
      "Epoch 74/100\n",
      "160/160 - 1s - loss: 0.2912 - accuracy: 0.8842 - val_loss: 0.3652 - val_accuracy: 0.8586\n",
      "Epoch 75/100\n",
      "160/160 - 1s - loss: 0.2862 - accuracy: 0.8886 - val_loss: 0.3758 - val_accuracy: 0.8576\n",
      "Epoch 76/100\n",
      "160/160 - 1s - loss: 0.2952 - accuracy: 0.8823 - val_loss: 0.3575 - val_accuracy: 0.8608\n",
      "Epoch 77/100\n",
      "160/160 - 1s - loss: 0.2932 - accuracy: 0.8824 - val_loss: 0.3696 - val_accuracy: 0.8590\n",
      "Epoch 78/100\n",
      "160/160 - 1s - loss: 0.2963 - accuracy: 0.8823 - val_loss: 0.3614 - val_accuracy: 0.8588\n",
      "Epoch 79/100\n",
      "160/160 - 1s - loss: 0.2950 - accuracy: 0.8842 - val_loss: 0.4098 - val_accuracy: 0.8494\n",
      "Epoch 80/100\n",
      "160/160 - 1s - loss: 0.2951 - accuracy: 0.8838 - val_loss: 0.3684 - val_accuracy: 0.8600\n",
      "Epoch 81/100\n",
      "160/160 - 1s - loss: 0.2912 - accuracy: 0.8856 - val_loss: 0.3607 - val_accuracy: 0.8562\n",
      "Epoch 82/100\n",
      "160/160 - 1s - loss: 0.2937 - accuracy: 0.8837 - val_loss: 0.3655 - val_accuracy: 0.8542\n",
      "Epoch 83/100\n",
      "160/160 - 1s - loss: 0.2861 - accuracy: 0.8864 - val_loss: 0.3774 - val_accuracy: 0.8426\n",
      "Epoch 84/100\n",
      "160/160 - 1s - loss: 0.2900 - accuracy: 0.8837 - val_loss: 0.3810 - val_accuracy: 0.8558\n",
      "Epoch 85/100\n",
      "160/160 - 1s - loss: 0.2887 - accuracy: 0.8859 - val_loss: 0.3673 - val_accuracy: 0.8580\n",
      "Epoch 86/100\n",
      "160/160 - 1s - loss: 0.2911 - accuracy: 0.8865 - val_loss: 0.3875 - val_accuracy: 0.8500\n",
      "Epoch 87/100\n",
      "160/160 - 1s - loss: 0.2810 - accuracy: 0.8917 - val_loss: 0.3721 - val_accuracy: 0.8544\n",
      "Epoch 88/100\n",
      "160/160 - 1s - loss: 0.2822 - accuracy: 0.8906 - val_loss: 0.3811 - val_accuracy: 0.8560\n",
      "Epoch 89/100\n",
      "160/160 - 2s - loss: 0.2881 - accuracy: 0.8856 - val_loss: 0.3682 - val_accuracy: 0.8538\n",
      "Epoch 90/100\n",
      "160/160 - 1s - loss: 0.2823 - accuracy: 0.8896 - val_loss: 0.3745 - val_accuracy: 0.8570\n",
      "Epoch 91/100\n",
      "160/160 - 1s - loss: 0.2890 - accuracy: 0.8860 - val_loss: 0.3861 - val_accuracy: 0.8564\n",
      "Epoch 92/100\n",
      "160/160 - 1s - loss: 0.2884 - accuracy: 0.8866 - val_loss: 0.3842 - val_accuracy: 0.8508\n",
      "Epoch 93/100\n",
      "160/160 - 1s - loss: 0.2868 - accuracy: 0.8884 - val_loss: 0.3838 - val_accuracy: 0.8442\n",
      "Epoch 94/100\n",
      "160/160 - 2s - loss: 0.2839 - accuracy: 0.8891 - val_loss: 0.3696 - val_accuracy: 0.8562\n",
      "Epoch 95/100\n",
      "160/160 - 1s - loss: 0.2851 - accuracy: 0.8893 - val_loss: 0.3843 - val_accuracy: 0.8580\n",
      "Epoch 96/100\n",
      "160/160 - 1s - loss: 0.2806 - accuracy: 0.8906 - val_loss: 0.4098 - val_accuracy: 0.8464\n",
      "Epoch 97/100\n",
      "160/160 - 1s - loss: 0.2828 - accuracy: 0.8882 - val_loss: 0.3874 - val_accuracy: 0.8536\n",
      "Epoch 98/100\n",
      "160/160 - 1s - loss: 0.2826 - accuracy: 0.8907 - val_loss: 0.3823 - val_accuracy: 0.8564\n",
      "Epoch 99/100\n",
      "160/160 - 1s - loss: 0.2859 - accuracy: 0.8886 - val_loss: 0.3751 - val_accuracy: 0.8534\n",
      "Epoch 100/100\n",
      "160/160 - 1s - loss: 0.2883 - accuracy: 0.8885 - val_loss: 0.3795 - val_accuracy: 0.8512\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(X_train, y_train, batch_size = 125, epochs = 100, verbose = 2, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3926 - accuracy: 0.8492\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.39255258440971375, 0.8492000102996826]"
      ]
     },
     "metadata": {},
     "execution_count": 173
    }
   ],
   "source": [
    "X_test = te_d_msv\n",
    "model2.evaluate(X_test, y_test, batch_size = 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}