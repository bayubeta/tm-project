{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "#-------------------------------\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg', disable = [\"tagger\", \"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "negative    12500\n",
       "positive    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "train_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\\begin{tabular}{ll}\n\\toprule\n                                            review & sentiment \\\\\n\\midrule\n Bromwell High is a cartoon comedy. It ran at t... &  positive \\\\\n Homelessness (or Houselessness as George Carli... &  positive \\\\\n Brilliant over-acting by Lesley Ann Warren. Be... &  positive \\\\\n This is easily the most underrated film inn th... &  positive \\\\\n This is not the typical Mel Brooks film. It wa... &  positive \\\\\n\\bottomrule\n\\end{tabular}\n\n"
     ]
    }
   ],
   "source": [
    "print(train_data[12500:12505].to_latex(index=False))"
   ]
  },
  {
   "source": [
    "# Using CountVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### CountVectorizer + MultinomialNB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total=  10.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing mnb, total=   0.1s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82     12500\n",
      "    positive       0.86      0.75      0.80     12500\n",
      "\n",
      "    accuracy                           0.81     25000\n",
      "   macro avg       0.82      0.81      0.81     25000\n",
      "weighted avg       0.82      0.81      0.81     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_count_mnb = Pipeline([(\"vectorizer\", CountVectorizer()), (\"mnb\", MultinomialNB())], verbose=True)\n",
    "pipe_count_mnb.fit(train_data['review'], train_data['sentiment'])\n",
    "pred_count_mnb = pipe_count_mnb.predict(test_data['review'])\n",
    "\n",
    "print(classification_report(test_data['sentiment'], pred_count_mnb, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "source": [
    "### CountVectorizer + LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total=  11.0s\n",
      "C:\\Users\\Bayu\\.conda\\envs\\tm\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Pipeline] ............ (step 2 of 2) Processing logreg, total=   6.2s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87     12500\n",
      "    positive       0.87      0.86      0.86     12500\n",
      "\n",
      "    accuracy                           0.86     25000\n",
      "   macro avg       0.86      0.86      0.86     25000\n",
      "weighted avg       0.86      0.86      0.86     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_count_logreg = Pipeline([(\"vectorizer\", CountVectorizer()), (\"logreg\", LogisticRegression(random_state=1234))], verbose=True)\n",
    "pipe_count_logreg.fit(train_data['review'], train_data['sentiment'])\n",
    "pred_count_logreg = pipe_count_logreg.predict(test_data['review'])\n",
    "\n",
    "print(classification_report(test_data['sentiment'], pred_count_logreg, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "source": [
    "### CountVectorizer + LinearSVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total=   9.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing SVC, total=   9.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85     12500\n",
      "    positive       0.85      0.84      0.84     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_count_SVC = Pipeline([(\"vectorizer\", CountVectorizer()), (\"SVC\", LinearSVC(random_state=1234))], verbose=True)\n",
    "pipe_count_SVC.fit(train_data['review'], train_data['sentiment'])\n",
    "pred_count_SVC = pipe_count_SVC.predict(test_data['review'])\n",
    "\n",
    "print(classification_report(test_data['sentiment'], pred_count_SVC, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "source": [
    "# Using TfidfVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### TfidfVectorizer + MultinomialNB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total=  10.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing mnb, total=   0.1s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.89      0.84     12500\n",
      "    positive       0.87      0.77      0.82     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.83      0.83      0.83     25000\n",
      "weighted avg       0.83      0.83      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_tfidf_mnb = Pipeline([(\"vectorizer\", TfidfVectorizer()), (\"mnb\", MultinomialNB())], verbose=True)\n",
    "pipe_tfidf_mnb.fit(train_data['review'], train_data['sentiment'])\n",
    "pred_tfidf_mnb = pipe_tfidf_mnb.predict(test_data['review'])\n",
    "\n",
    "print(classification_report(test_data['sentiment'], pred_tfidf_mnb, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "source": [
    "#### TfidfVectorizer + LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total=  10.4s\n",
      "[Pipeline] ............ (step 2 of 2) Processing logreg, total=   3.4s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88     12500\n",
      "    positive       0.88      0.88      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_tfidf_logreg = Pipeline([(\"vectorizer\", TfidfVectorizer()), (\"logreg\", LogisticRegression(random_state=1234))], verbose=True)\n",
    "pipe_tfidf_logreg.fit(train_data['review'], train_data['sentiment'])\n",
    "predC_tfidf_logreg = pipe_tfidf_logreg.predict(test_data['review'])\n",
    "\n",
    "print(classification_report(test_data['sentiment'], predC_tfidf_logreg, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "source": [
    "### TfidfVectorizer + SVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total=   9.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing SVC, total=   0.8s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88     12500\n",
      "    positive       0.89      0.87      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_tfidf_SVC = Pipeline([(\"vectorizer\", TfidfVectorizer()), (\"SVC\", LinearSVC(random_state=1234))], verbose=True)\n",
    "pipe_tfidf_SVC.fit(train_data['review'], train_data['sentiment'])\n",
    "pred_tfidf_SVC = pipe_tfidf_SVC.predict(test_data['review'])\n",
    "\n",
    "print(classification_report(test_data['sentiment'], pred_tfidf_SVC, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "source": [
    "# Using MeanSentenceVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class MeanSentenceVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def tokenizer(self, sentence):\n",
    "        doc = nlp(sentence)\n",
    "        preprocessed = [token.text for token in doc]\n",
    "        return preprocessed\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array(\n",
    "            [np.mean([nlp.vocab[word].vector for word in self.tokenizer(sentence)], axis=0) for sentence in tqdm(X)]\n",
    "            )"
   ]
  },
  {
   "source": [
    "### MeanSentenceVectorizer + LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f393c367a2fb4d7b9055146b4eb459df"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.3min\n",
      "[Pipeline] ............ (step 2 of 2) Processing logreg, total=   1.7s\n",
      "C:\\Users\\Bayu\\.conda\\envs\\tm\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8af3cf7c3d54bb390296ec67ee8b27a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85     12500\n",
      "    positive       0.85      0.84      0.85     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_msv_logreg = Pipeline([(\"vectorizer\", MeanSentenceVectorizer()), (\"logreg\", LogisticRegression(random_state=1234))], verbose=True)\n",
    "pipe_msv_logreg.fit(train_data['review'], train_data['sentiment'])\n",
    "pred_ms_logreg = pipe_msv_logreg.predict(test_data['review'])\n",
    "\n",
    "print(classification_report(test_data['sentiment'], pred_msv_logreg, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "source": [
    "### MeanSentenceVectorizer + SVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "514d842bdc3642efbe4ee0a0150d6df0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing SVC, total=  10.7s\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb69def859c74f7faf67efc4a9dcc9d6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85     12500\n",
      "    positive       0.86      0.85      0.85     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_msv_SVC = Pipeline([(\"vectorizer\", MeanSentenceVectorizer()), (\"SVC\", LinearSVC(random_state=1234))], verbose=True)\n",
    "pipe_msv_SVC.fit(train_data['review'], train_data['sentiment'])\n",
    "pred_msv_SVC = pipe_msv_SVC.predict(test_data['review'])\n",
    "\n",
    "print(classification_report(test_data['sentiment'], pred_msv_SVC, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "source": [
    "# Using DistilBERT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' \\nfrom transformers import DistilBertTokenizer, TFDistilBertModel\\nimport tensorflow as tf\\n\\ntokenizer = DistilBertTokenizer.from_pretrained(\\'distilbert-base-uncased\\')\\nmodel = TFDistilBertModel.from_pretrained(\\'distilbert-base-uncased\\')\\n\\n###############################\\n# Slice the data for trials\\nr = int(1/2 * len(train_data))\\n\\ntr_d = pd.concat([train_data[:r], train_data[12500:(12500+r)]])\\nte_d = pd.concat([test_data[:r], test_data[12500:(12500+r)]])\\n###############################\\n\\ndef embed_sentences(X, maxlen=512):\\n    # tokenize sentences\\n    tokenized = []\\n    for sentence in tqdm(X, desc=\\'Tokenizing sentences\\'):\\n        token_vec = tokenizer(sentence, return_tensors=\"tf\", truncation=True, padding=\\'max_length\\', max_length=maxlen)[\\'input_ids\\']\\n        tokenized.append(token_vec)\\n    tokenized = tf.convert_to_tensor(tf.squeeze(tokenized))\\n\\n    # embedding sentences\\n    vecs = []\\n    batches = list(tf.split(tokenized, 5000))\\n    for batch in tqdm(batches, desc=\\'Processing sentences\\'):\\n        lhs = model(batch).last_hidden_state[:,0,:]\\n        vecs.append(lhs)\\n    return np.concatenate(vecs)\\n\\nX_train = embed_sentences(tr_d[\\'review\\'])\\nnp.save(\\'X_train\\', X_train)\\n\\nX_test = embed_sentences(te_d[\\'review\\'])\\nnp.save(\\'X_test\\', X_test)\\n '"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# code for processing sentence to sentence embedding\n",
    "\"\"\" \n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "###############################\n",
    "# Slice the data for trials\n",
    "r = int(1/2 * len(train_data))\n",
    "\n",
    "tr_d = pd.concat([train_data[:r], train_data[12500:(12500+r)]])\n",
    "te_d = pd.concat([test_data[:r], test_data[12500:(12500+r)]])\n",
    "###############################\n",
    "\n",
    "def embed_sentences(X, maxlen=512):\n",
    "    # tokenize sentences\n",
    "    tokenized = []\n",
    "    for sentence in tqdm(X, desc='Tokenizing sentences'):\n",
    "        token_vec = tokenizer(sentence, return_tensors=\"tf\", truncation=True, padding='max_length', max_length=maxlen)['input_ids']\n",
    "        tokenized.append(token_vec)\n",
    "    tokenized = tf.convert_to_tensor(tf.squeeze(tokenized))\n",
    "\n",
    "    # embedding sentences\n",
    "    vecs = []\n",
    "    batches = list(tf.split(tokenized, 5000))\n",
    "    for batch in tqdm(batches, desc='Processing sentences'):\n",
    "        lhs = model(batch).last_hidden_state[:,0,:]\n",
    "        vecs.append(lhs)\n",
    "    return np.concatenate(vecs)\n",
    "\n",
    "X_train = embed_sentences(tr_d['review'])\n",
    "np.save('X_train', X_train)\n",
    "\n",
    "X_test = embed_sentences(te_d['review'])\n",
    "np.save('X_test', X_test)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vectors\n",
    "X_train, X_test = np.load('X_train.npy'),  np.load('X_test.npy')"
   ]
  },
  {
   "source": [
    "### DistilBERT + LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bayu\\.conda\\envs\\tm\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.85     12500\n",
      "    positive       0.85      0.84      0.85     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db_logreg = LogisticRegression(random_state=1234).fit(X_train, train_data['sentiment'])\n",
    "pred_db_logreg = db_logreg.predict(X_test)\n",
    "print(classification_report(test_data['sentiment'], pred_db_logreg, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "source": [
    "### DistilBERT + SVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bayu\\.conda\\envs\\tm\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85     12500\n",
      "    positive       0.85      0.85      0.85     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db_SVC = LinearSVC(random_state=1234).fit(X_train, train_data['sentiment'])\n",
    "pred_db_SVC = db_SVC.predict(X_test)\n",
    "print(classification_report(test_data['sentiment'], pred_db_SVC, target_names = train_data['sentiment'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = {'MultinomialNB': [0.82, 0.83, '-', '-'],\n",
    "        'LogisticRegression': [0.86, 0.88, 0.85, 0.85],\n",
    "        'LinearSVC':[0.85, 0.88, 0.85, 0.85]}\n",
    "acc_df = pd.DataFrame(acc, columns = ['MultinomialNB', 'LogisticRegression', 'LinearSVC'],\n",
    "                        index=['CountVectorizer', 'TfidfVectorizer', 'MeanSentenceVectorizer', 'DistilBERT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       MultinomialNB  LogisticRegression  LinearSVC\n",
       "CountVectorizer                 0.82                0.86       0.85\n",
       "TfidfVectorizer                 0.83                0.88       0.88\n",
       "MeanSentenceVectorizer             -                0.85       0.85\n",
       "DistilBERT                         -                0.85       0.85"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MultinomialNB</th>\n      <th>LogisticRegression</th>\n      <th>LinearSVC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>CountVectorizer</th>\n      <td>0.82</td>\n      <td>0.86</td>\n      <td>0.85</td>\n    </tr>\n    <tr>\n      <th>TfidfVectorizer</th>\n      <td>0.83</td>\n      <td>0.88</td>\n      <td>0.88</td>\n    </tr>\n    <tr>\n      <th>MeanSentenceVectorizer</th>\n      <td>-</td>\n      <td>0.85</td>\n      <td>0.85</td>\n    </tr>\n    <tr>\n      <th>DistilBERT</th>\n      <td>-</td>\n      <td>0.85</td>\n      <td>0.85</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "acc_df"
   ]
  }
 ]
}