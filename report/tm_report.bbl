\begin{thebibliography}{17}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Jurafsky and Martin(2009)]{Jurafsky2009}
Dan Jurafsky and James~H. Martin.
\newblock \emph{Speech and language processing : an introduction to natural
  language processing, computational linguistics, and speech recognition}.
\newblock Pearson Prentice Hall, Upper Saddle River, N.J., 2009.
\newblock ISBN 9780131873216 0131873210.
\newblock URL
  \url{http://www.amazon.com/Speech-Language-Processing-2nd-Edition/dp/0131873210/ref=pd_bxgy_b_img_y}.

\bibitem[Pennington et~al.(2014)Pennington, Socher, and
  Manning]{pennington2014glove}
Jeffrey Pennington, Richard Socher, and Christopher~D. Manning.
\newblock Glove: Global vectors for word representation.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  pages 1532--1543, 2014.
\newblock URL \url{http://www.aclweb.org/anthology/D14-1162}.

\bibitem[Mikolov et~al.(2013)Mikolov, Chen, Corrado, and
  Dean]{mikolov2013efficient}
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
\newblock Efficient estimation of word representations in vector space, 2013.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{devlin-etal-2019-bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 4171--4186,
  Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1423}.
\newblock URL \url{https://www.aclweb.org/anthology/N19-1423}.

\bibitem[Honnibal et~al.(2020)Honnibal, Montani, Van~Landeghem, and
  Boyd]{spacy}
Matthew Honnibal, Ines Montani, Sofie Van~Landeghem, and Adriane Boyd.
\newblock {spaCy: Industrial-strength Natural Language Processing in Python},
  2020.
\newblock URL \url{https://doi.org/10.5281/zenodo.1212303}.

\bibitem[Sanh et~al.(2020)Sanh, Debut, Chaumond, and Wolf]{sanh2020distilbert}
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf.
\newblock Distilbert, a distilled version of bert: smaller, faster, cheaper and
  lighter, 2020.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos,
  Cournapeau, Brucher, Perrot, and Duchesnay]{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830,
  2011.

\bibitem[Maas et~al.(2011)Maas, Daly, Pham, Huang, Ng, and
  Potts]{maas-etal-2011-learning}
Andrew~L. Maas, Raymond~E. Daly, Peter~T. Pham, Dan Huang, Andrew~Y. Ng, and
  Christopher Potts.
\newblock Learning word vectors for sentiment analysis.
\newblock In \emph{Proceedings of the 49th Annual Meeting of the Association
  for Computational Linguistics: Human Language Technologies}, pages 142--150,
  Portland, Oregon, USA, June 2011. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/P11-1015}.

\bibitem[Bengio et~al.(2003)Bengio, Ducharme, Vincent, and Janvin]{bengio03}
Yoshua Bengio, R\'{e}jean Ducharme, Pascal Vincent, and Christian Janvin.
\newblock A neural probabilistic language model.
\newblock \emph{J. Mach. Learn. Res.}, 3\penalty0 (null):\penalty0 1137–1155,
  March 2003.
\newblock ISSN 1532-4435.

\bibitem[Mikolov et~al.(2013a)Mikolov, Sutskever, Chen, Corrado, and
  Dean]{mikolov2013distributed}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean.
\newblock Distributed representations of words and phrases and their
  compositionality, 2013a.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need, 2017.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{hinton2015distilling}
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
\newblock Distilling the knowledge in a neural network, 2015.

\bibitem[Hastie et~al.(2001)Hastie, Tibshirani, and
  Friedman]{hastie01statisticallearning}
Trevor Hastie, Robert Tibshirani, and Jerome Friedman.
\newblock \emph{The Elements of Statistical Learning}.
\newblock Springer Series in Statistics. Springer New York Inc., New York, NY,
  USA, 2001.

\bibitem[Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts]{socher-etal-2013-recursive}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher~D. Manning,
  Andrew Ng, and Christopher Potts.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In \emph{Proceedings of the 2013 Conference on Empirical Methods in
  Natural Language Processing}, pages 1631--1642, Seattle, Washington, USA,
  October 2013. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/D13-1170}.

\bibitem[Wolf et~al.(2020)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, Davison, Shleifer, von Platen, Ma, Jernite, Plu, Xu,
  Scao, Gugger, Drame, Lhoest, and Rush]{wolf-etal-2020-transformers}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe
  Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
  Plu, Canwen Xu, Teven~Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
  and Alexander~M. Rush.
\newblock Transformers: State-of-the-art natural language processing.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, pages 38--45, Online,
  October 2020. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/2020.emnlp-demos.6}.

\bibitem[Iyyer et~al.(2015)Iyyer, Manjunatha, Boyd-Graber, and
  Daum{\'e}~III]{iyyer-etal-2015-deep}
Mohit Iyyer, Varun Manjunatha, Jordan Boyd-Graber, and Hal Daum{\'e}~III.
\newblock Deep unordered composition rivals syntactic methods for text
  classification.
\newblock In \emph{Proceedings of the 53rd Annual Meeting of the Association
  for Computational Linguistics and the 7th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, pages 1681--1691,
  Beijing, China, July 2015. Association for Computational Linguistics.
\newblock \doi{10.3115/v1/P15-1162}.
\newblock URL \url{https://www.aclweb.org/anthology/P15-1162}.

\bibitem[Arora et~al.(2017)Arora, Liang, and Ma]{Arora2017ASB}
Sanjeev Arora, Yingyu Liang, and Tengyu Ma.
\newblock A simple but tough-to-beat baseline for sentence embeddings.
\newblock In \emph{ICLR}, 2017.

\end{thebibliography}
